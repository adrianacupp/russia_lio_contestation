{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, random, codecs, json, pickle\n",
    "seed = 99\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim.test.utils \n",
    "import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pyvis.network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mm/gw92vpys6rggjz_4z42s244w0000gn/T/ipykernel_4344/2111997776.py:1: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "from imp import reload\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and parse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the dataframe\n",
    "lavrov = pd.read_pickle('/Users/adrianacuppuleri/Desktop/GITHUB ADRIANA/Illiberal_discourse/data/corpus_adriana/corpus_lavrov/lavrov_5_col.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5208 entries, 0 to 5212\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   speaker  5208 non-null   object        \n",
      " 1   date     5208 non-null   datetime64[ns]\n",
      " 2   url      5208 non-null   object        \n",
      " 3   title    5208 non-null   object        \n",
      " 4   text     5208 non-null   object        \n",
      "dtypes: datetime64[ns](1), object(4)\n",
      "memory usage: 244.1+ KB\n"
     ]
    }
   ],
   "source": [
    "lavrov.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lavrov_clean = pd.read_pickle('/Users/adrianacuppuleri/Desktop/GITHUB ADRIANA/Illiberal_discourse/data/corpus_adriana/corpus_lavrov/lavrov_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5208 entries, 0 to 5212\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   speaker     5208 non-null   object        \n",
      " 1   date        5208 non-null   datetime64[ns]\n",
      " 2   url         5208 non-null   object        \n",
      " 3   title       5208 non-null   object        \n",
      " 4   text        5208 non-null   object        \n",
      " 5   word_count  5208 non-null   int64         \n",
      " 6   lemma       5208 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(5)\n",
      "memory usage: 325.5+ KB\n"
     ]
    }
   ],
   "source": [
    "lavrov_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lavrov_clean.rename(columns={'text':'text_clean'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_add = lavrov_clean['text_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5208 entries, 0 to 5212\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   speaker     5208 non-null   object        \n",
      " 1   date        5208 non-null   datetime64[ns]\n",
      " 2   url         5208 non-null   object        \n",
      " 3   title       5208 non-null   object        \n",
      " 4   text        5208 non-null   object        \n",
      " 5   text_clean  5208 non-null   object        \n",
      "dtypes: datetime64[ns](1), object(5)\n",
      "memory usage: 284.8+ KB\n"
     ]
    }
   ],
   "source": [
    "lavrov_concatenated = pd.concat([lavrov, col_to_add], axis=1)\n",
    "lavrov_concatenated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lavrov_concatenated = lavrov_concatenated[['date','url','title','speaker','text','text_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lavrov_concatenated.to_pickle('/Users/adrianacuppuleri/Desktop/GITHUB ADRIANA/Illiberal_discourse/data/corpus_adriana/corpus_president_of_russia/lavrov_concatenated.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lavrov_concatenated = pd.read_pickle('/Users/adrianacuppuleri/Desktop/GITHUB ADRIANA/Illiberal_discourse/data/corpus_adriana/corpus_president_of_russia/lavrov_concatenated.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/Users/adrianacuppuleri/Desktop/GITHUB ADRIANA/Illiberal_discourse/data/corpus_adriana/corpus_president_of_russia'\n",
    "names = ['somi_concatenated','news_concatenated', 'messages_to_federal_assembly','interviews_concatenated']\n",
    "\n",
    "for name in names:\n",
    "    file_path = os.path.join(output_dir, f\"{name}.pkl\")\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        df = pd.read_pickle(file)\n",
    "        globals()[name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 691 entries, 0 to 690\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   date        691 non-null    object\n",
      " 1   url         691 non-null    object\n",
      " 2   title       691 non-null    object\n",
      " 3   speaker     691 non-null    object\n",
      " 4   text        691 non-null    object\n",
      " 5   text_clean  691 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 32.5+ KB\n"
     ]
    }
   ],
   "source": [
    "somi_concatenated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114 entries, 0 to 113\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   date        114 non-null    object\n",
      " 1   url         114 non-null    object\n",
      " 2   title       114 non-null    object\n",
      " 3   speaker     114 non-null    object\n",
      " 4   text        114 non-null    object\n",
      " 5   text_clean  114 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 5.5+ KB\n"
     ]
    }
   ],
   "source": [
    "interviews_concatenated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14 entries, 0 to 13\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   date        14 non-null     object\n",
      " 1   URL         14 non-null     object\n",
      " 2   title       14 non-null     object\n",
      " 3   speaker     14 non-null     object\n",
      " 4   text        14 non-null     object\n",
      " 5   text_clean  14 non-null     object\n",
      "dtypes: object(6)\n",
      "memory usage: 800.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "messages_to_federal_assembly.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_to_federal_assembly.rename(columns={'URL':'url'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 754 entries, 0 to 753\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   date         754 non-null    object\n",
      " 1   URL          754 non-null    object\n",
      " 2   description  754 non-null    object\n",
      " 3   speaker      754 non-null    object\n",
      " 4   text         754 non-null    object\n",
      " 5   text_clean   754 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 35.5+ KB\n"
     ]
    }
   ],
   "source": [
    "news_concatenated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_concatenated.rename(columns={'URL':'url'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_concatenated.rename(columns={'description':'title'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each dataset, add a col word_count\n",
    "#combine the dfs in a list\n",
    "dfs = [somi_concatenated, messages_to_federal_assembly, interviews_concatenated, news_concatenated,lavrov_concatenated]\n",
    "# iterate over each dataframe and extract the word count for the 'text_clean' column and cut row where word_count == 0\n",
    "for df in dfs:\n",
    "    df['word_count'] = df['text_clean'].apply(lambda x: len(x.split()))\n",
    "    df.drop(df[df['word_count'] == 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([somi_concatenated, messages_to_federal_assembly, interviews_concatenated, news_concatenated,lavrov_concatenated], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6779 entries, 0 to 5212\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   date        6779 non-null   object\n",
      " 1   url         6779 non-null   object\n",
      " 2   title       6779 non-null   object\n",
      " 3   speaker     6779 non-null   object\n",
      " 4   text        6779 non-null   object\n",
      " 5   text_clean  6779 non-null   object\n",
      " 6   word_count  6779 non-null   int64 \n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 423.7+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as pickle\n",
    "merged_df.to_pickle('/Users/adrianacuppuleri/Desktop/GITHUB ADRIANA/Illiberal_discourse/data/corpus_adriana/corpus_president_of_russia/merged_df.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing for word embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "col text_clean is based on this function:\n",
    "\n",
    "def clean(text):\n",
    "    # replace actual newline characters \\n with a space\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    #replace Д.Медведев:|В.Путин: with a white space\n",
    "    text = re.sub(r'(Д\\.Медведев:|В\\.Путин:)', ' ', text)\n",
    "    # replace everything non-alphanumeric with a space\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    # replace two or more dots with one\n",
    "    text = re.sub(r'\\.{2,}', ' ', text)\n",
    "    # replace sequences of white spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # replace \\xa0 with a white space\n",
    "    text = re.sub(r'\\xa0', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/Users/adrianacuppuleri/Desktop/GITHUB ADRIANA/Illiberal_discourse/data/corpus_adriana/corpus_president_of_russia/merged_df.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunk the df into 4 time frame according to presidential mandate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid search with the best word2vec model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loop on each time frame and make bootstrap sampling and word2vec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then run again the loop but this time just for the interested word"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the cosine similarity between the matrix of entire corpus and the matrix of the single word"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the mean of the bootstrap sample for vectors of sigle word and for vectors of all words from the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
